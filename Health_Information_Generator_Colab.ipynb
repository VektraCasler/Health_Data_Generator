{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Health_Information_Generator_Colab.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1SMdXqYRQaZTdjs58Cp1W2ju9IhlUv-og","authorship_tag":"ABX9TyMTpsK1gn/cuCjGnAqz/XPl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NIWqnWB0YvXd"},"source":["This is the \"hacking\" version of the Health Information Generator, in interactive Python notebook format.\n","\n","Once drive is mounted in files, it looks for the files OUTPUT and REFERENCE in the main level.\n","\n","Tony's Quick Notes:\n","\n","\n","*   For eventual speed improvements (premature optimization is the root of all evil!) there are several lists[] that we can change to unmutable sets{} in the future with O(1) lookup time vs. O(n)\n","*   Currently exploring how Colab does referential file loading...\n","* Add type hints\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"4l-pvayee8RT","executionInfo":{"status":"ok","timestamp":1628726347111,"user_tz":240,"elapsed":166,"user":{"displayName":"Tony Cardillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtWWzn-vMnDwzFeWnHtHY15n7iG1LJRoHtaEPvlQ=s64","userId":"03815610467705784385"}}},"source":["# Imports\n","\n","import random\n","import datetime\n","import pandas as pd\n","from tqdm import tqdm\n","import math"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"8pf5mwrHcK1u","executionInfo":{"status":"ok","timestamp":1628726342067,"user_tz":240,"elapsed":211,"user":{"displayName":"Tony Cardillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtWWzn-vMnDwzFeWnHtHY15n7iG1LJRoHtaEPvlQ=s64","userId":"03815610467705784385"}}},"source":["# File names and global variables on Google Drive\n","output_file_name = '/content/drive/MyDrive/OUTPUT/person_list.csv'\n","race_distribution_file = '/content/drive/MyDrive/REFERENCE/ancestry/race_distribution.csv'\n","ethnicity_distribution_file = '/content/drive/MyDrive/REFERENCE/ancestry/ethnicity_distribution.csv'\n","age_category_distribution_file = '/content/drive/MyDrive/REFERENCE/age/age_category_distribution.csv'\n","zip_code_distribution_file = '/content/drive/MyDrive/REFERENCE/location/population_by_zip_code.csv'\n","usa_addresses_file = '/content/drive/MyDrive/REFERENCE/location/usa_addresses.csv'\n","person_names_file = '/content/drive/MyDrive/REFERENCE/name/person_names.csv'\n","surnames_asian_file = '/content/drive/MyDrive/REFERENCE/surname/surnames_asian.csv'\n","surnames_black_file = '/content/drive/MyDrive/REFERENCE/surname/surnames_black.csv'\n","surnames_generic_file = '/content/drive/MyDrive/REFERENCE/surname/surnames_generic.csv'\n","surnames_hispanic_file = '/content/drive/MyDrive/REFERENCE/surname/surnames_hispanic.csv'\n","surnames_native_file = '/content/drive/MyDrive/REFERENCE/surname/surnames_native.csv'\n","surnames_white_file = '/content/drive/MyDrive/REFERENCE/surname/surnames_white.csv'\n","email_domains_file = '/content/drive/MyDrive/REFERENCE/email/email_domains.csv'\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"tuMDy0V8csDo","colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"status":"error","timestamp":1628726413364,"user_tz":240,"elapsed":9806,"user":{"displayName":"Tony Cardillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtWWzn-vMnDwzFeWnHtHY15n7iG1LJRoHtaEPvlQ=s64","userId":"03815610467705784385"}},"outputId":"0f30a45e-2680-4961-b597-ebc2a4f66f42"},"source":["# read source files into memory\n","DF_race_distribution = pd.read_csv(race_distribution_file)\n","DF_ethnicity_distribution = pd.read_csv(ethnicity_distribution_file)\n","DF_age_category_distribution = pd.read_csv(age_category_distribution_file)\n","DF_zip_code_distribution = pd.read_csv(zip_code_distribution_file)\n","DF_usa_addresses = pd.read_csv(usa_addresses_file)\n","DF_person_names = pd.read_csv(person_names_file)\n","DF_surname_asian = pd.read_csv(surnames_asian_file)\n","DF_surname_black = pd.read_csv(surnames_black_file)\n","DF_surname_generic = pd.read_csv(surnames_generic_file)\n","DF_surname_hispanic = pd.read_csv(surnames_hispanic_file)\n","DF_surname_native = pd.read_csv(surnames_native_file)\n","DF_surname_white = pd.read_csv(surnames_white_file)\n","DF_email_domains = pd.read_csv(email_domains_file)\n","\n","# Global Variables\n","number_of_records = 1000000 # Number of records to generate\n","person_sexes = [\"Male\", \"Female\"]\n","SSN_list = ['000-00-0000']  # Track SSN values to ensure no duplicates for person, with 000-00-0000 as a guaranteed 'not used'\n","MRN_list = ['M00000000']\n","\n","# permitted phone area codes\n","# TODO - eventual optimiztion is to make this a set{}\n","usable_area_codes = [201,202,203,205,206,207,208,209,210,212,213,214,215,216,217,218,219,220,221,223,224,225,227,228,229,230,231,232,234,235,237,238,239,240,241,242,243,245,246,247,248,251,252,253,254,256,257,258,259,260,261,262,264,265,267,268,269,270,271,272,273,274,275,276,278,279,280,281,282,283,284,285,286,287,289,301,302,303,304,305,307,308,309,310,312,313,314,315,316,317,318,319,320,321,323,324,325,326,327,328,329,330,331,332,334,335,336,337,338,339,340,341,342,345,346,347,348,349,350,351,352,353,356,357,358,359,360,361,362,363,364,369,380,381,383,384,385,386,389,401,402,403,404,405,406,407,408,409,410,412,413,414,415,416,417,418,419,420,421,423,424,425,426,427,428,429,430,431,432,434,435,436,437,438,439,440,441,442,443,445,446,447,448,449,450,451,452,453,454,456,457,458,459,460,461,462,463,464,465,467,468,469,470,471,472,473,474,475,476,478,479,480,481,482,483,484,485,486,487,489,501,502,503,504,505,507,508,509,510,512,513,515,516,517,518,520,530,531,534,536,537,539,540,541,551,557,559,560,561,562,563,564,565,567,568,570,571,572,573,574,575,576,580,582,583,585,586,601,602,603,605,606,607,608,609,610,612,614,615,616,617,618,619,620,621,623,624,625,626,627,628,629,630,631,632,634,635,636,637,638,640,641,642,643,645,646,648,649,650,651,652,653,654,656,657,658,659,660,661,662,663,664,665,667,668,669,670,671,673,674,675,676,678,679,680,681,682,684,685,686,687,689,701,702,703,704,706,707,708,712,713,714,715,716,717,718,719,720,721,723,724,725,726,727,728,729,730,731,732,734,735,736,737,738,739,740,741,743,745,746,747,748,749,750,751,752,754,756,757,758,759,760,761,762,763,764,765,767,768,769,770,771,772,773,774,775,776,779,781,783,784,785,786,787,789,801,802,803,804,805,806,808,809,810,812,813,814,815,816,817,818,820,821,823,824,826,827,828,829,830,831,832,834,835,836,837,838,839,840,841,842,843,845,846,847,848,849,850,851,852,853,854,856,857,858,859,860,861,862,863,864,865,868,869,870,871,872,874,875,876,878,901,903,904,906,907,908,909,910,912,913,914,915,916,917,918,919,920,921,923,924,925,926,927,928,929,930,931,932,934,935,936,937,938,939,940,941,943,945,946,947,948,949,951,952,953,954,956,957,958,959,970,971,972,973,974,975,976,978,979,980,981,982,983,984,985,986,987,989]"],"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-145d05a3818c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mDF_zip_code_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_code_distribution_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mDF_usa_addresses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musa_addresses_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mDF_person_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson_names_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mDF_surname_asian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurnames_asian_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mDF_surname_black\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurnames_black_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/REFERENCE/name/person_names.csv'"]}]},{"cell_type":"markdown","metadata":{"id":"M0IvOsBJcn8b"},"source":["Functions"]},{"cell_type":"code","metadata":{"id":"Ar40uZf5eR_l"},"source":["def generate_race():\n","\n","    ''' Randomly choses a person's race/heritage, based on US population 2010 census data. '''\n","    \n","    person_race = random.choices(DF_race_distribution[\"identification\"], weights = DF_race_distribution[\"weight\"])[0]\n","\n","    if person_race in ['White','Mixed','Unreported']:\n","\n","        person_ethnicity = random.choices(DF_ethnicity_distribution['identification'], weights = DF_ethnicity_distribution['weight'])[0]\n","\n","    else:\n","\n","        person_ethnicity = \"Unreported\"\n","\n","    return (str(person_race), str(person_ethnicity))\n","\n","\n","def generate_sex():\n","\n","    ''' Randomly generates a person sex, with only male/female options. '''\n","\n","    # Eventual optimization will be to randomly select a bit ( 0 = female (biological default); 1 = male )\n","    # and return string \"Female\" or \"Male\" based off bit -> avoids calling string functions\n","    return random.choice(person_sexes).strip().capitalize()\n","\n","\n","def generate_age(person_sex):\n","\n","    ''' Generates a random person age, according to population distributions from 2010 US census data. '''\n","\n","    if person_sex == \"Male\":\n","        category_weights = DF_age_category_distribution[\"male_count\"]\n","    else:\n","        category_weights = DF_age_category_distribution[\"female_count\"]\n","\n","    person_age_category = int(random.choices(DF_age_category_distribution[\"age_floor\"], weights = category_weights)[0])\n","\n","    return (person_age_category + random.choice(range(5)))\n","\n","\n","def generate_SSN():\n","\n","    ''' Generates a random SSN, ensures that it is not all 0's, records the new SSN into a list (to ensure a unique identifier for the person), and returns the value. '''\n","\n","    AAA = str(random.randint(0,9)) + str(random.randint(0,9)) + str(random.randint(0,9))\n","    GG = str(random.randint(0,9)) + str(random.randint(0,9))\n","    SSSS = str(random.randint(0,9)) + str(random.randint(0,9)) + str(random.randint(0,9)) + str(random.randint(0,9))\n","    SSN = AAA + \"-\" + GG + \"-\" + SSSS\n","\n","    return SSN\n","\n","\n","def generate_surname(person_race, person_ethnicity, person_sex):\n","\n","    ''' Randomly generates a person's surname from 2010 census data, and randomly hyphenates last names for data variety.  '''\n","\n","    # Select proper surname list, based on ancestry\n","    if person_race == 'White':\n","        DF_surname = DF_surname_white\n","    elif person_race == 'Black':\n","        DF_surname = DF_surname_black\n","    elif person_race == 'Native American':\n","        DF_surname = DF_surname_native\n","    elif person_race in ['Asian','Pacific Islander']:\n","        DF_surname = DF_surname_asian\n","    else:\n","        DF_surname = DF_surname_generic\n","    if person_ethnicity == 'Hispanic':\n","        DF_surname = DF_surname_hispanic\n","\n","    # typical name\n","    hyphenate = False   \n","    person_surname = str(random.choices(DF_surname[\"Name\"], weights = DF_surname[\"Count\"])[0]).strip().capitalize()\n","\n","    # These values approximate the chance of a hyphenated name (Yet to find reliable data.  Fabricating values.)\n","    if person_sex == \"Female\":\n","        if random.random() < 0.03: # 3% chance\n","            hyphenate = True\n","    else:\n","        if random.random() < 0.001: # 0.1% chance\n","            hyphenate = True\n","\n","    # Loop to choose another name, but not the same name (Eg. No 'Lopez-Lopez' permitted.)\n","    while hyphenate:\n","\n","        person_surname_2 = str(random.choices(DF_surname[\"Name\"], weights = DF_surname[\"Count\"])[0]).strip().capitalize()\n","\n","        if person_surname_2 != person_surname:\n","            person_surname += \"-\" + person_surname_2\n","            hyphenate = False\n","\n","    return person_surname\n","\n","\n","def generate_name(person_sex, year_of_birth):\n","\n","    # No SSN data yet for 2021, using 2020 data\n","    if int(year_of_birth) >= 2021:\n","        year_of_birth = 2020\n","\n","    # Slice the master names dataframe for the birth year\n","    names_list = DF_person_names[DF_person_names[\"year\"] == int(year_of_birth)]\n","\n","    # Eliminate portion of list for other gender\n","    names_list = names_list[names_list[\"sex\"] == str(person_sex)[0]]\n","\n","    # Use weighted choice method in random module\n","    return str(random.choices(list(names_list[\"name\"]), weights = list(names_list[\"count\"]))[0]).strip().capitalize()\n","\n","\n","def generate_DOB(person_age):\n","    \n","    \"\"\" Subtracts person's age in days, as well as a random number of days between 0 and 364, from today's date, to generate a date of birth for the person. \"\"\"\n","    \n","    return str(datetime.date.today() - datetime.timedelta(days = 365 * float(person_age)) - datetime.timedelta(days=random.random() * 365))\n","\n","\n","def generate_zip_code():\n","\n","    ''' Return a random zip code, based on 2010 Census population data. '''\n","\n","    zip_code = random.choices(DF_zip_code_distribution['zip_code'], weights = DF_zip_code_distribution['population'])\n","\n","    return(str(zip_code[0]).zfill(5))\n","\n","\n","def generate_address(zip_code, residence):\n","\n","    ''' Return a randomly chosen street address, using zip_code and web-scraped data. Residence is a boolean value to denote a person's home, and enable apartment numbers or more complex street numbers.  (Non-commercial)'''\n","\n","    # slice the full address DF into matches based on zip_code\n","    DF_possible_addresses = DF_usa_addresses[DF_usa_addresses['zip_code'] == zip_code]\n","\n","    # In case the search comes up with nothing\n","    if DF_possible_addresses.shape[0] == 0:\n","        DF_add_me = pd.DataFrame(['00000','STATE','COUNTY','CITY','STREET'], columns = ['zip_code','state','county','city','street'])\n","        DF_possible_addresses.append(DF_add_me, ignore_index=True)\n","\n","    # get a random index value of the possible choices\n","    choose_me = random.randint(0, DF_possible_addresses.shape[0]-1)\n","\n","    # Then extract that row from the dataframe, based on the index value\n","    address = DF_possible_addresses[choose_me].squeeze()\n","    print(address)\n","\n","    # chop up the line into separate variables\n","\n","    address_country = 'United States'\n","    address_state = address[1]\n","    address_county = address[2]\n","    address_city = address[3]\n","    address_street = address[4]\n","    apartment = ''\n","\n","    # Generate a bunch of random numbers, letters and apartment combinations for residences\n","    if residence:\n","        street_number = random.randint(1, 10000)\n","        if random.choices([True,False], weights = [1, 7])[0]:\n","            apartment = int(random.choices(range(1,25), weights = range(25,1,-1))[0])\n","            apartment += int(random.choices([0,100,200,300,400,500,600,700,800,900], weights = [50,9,8,7,6,5,4,3,2,1])[0])\n","            apartment = str('Apt ' + str(random.choices(['','A-','B-','C-','D-','E-','F-','G-','H-','I-'], weights = [50,9,8,7,6,5,4,3,2,1])[0]) + str(apartment))\n","    # Commercial address numbers are much more streamlined and likely to be a multiple of 100\n","    else:\n","        street_number = random.randrange(100, 10000, 100)\n","\n","    # concatenate all the strings\n","    address_street = (str(street_number) + ' ' + str(address_street).strip() + ' ' + apartment).strip()\n","\n","    # return the address values as discrete fields\n","    return(address_street, address_city, address_county, address_state, address_country)\n","\n","\n","def generate_MRN():\n","\n","    ''' Randomly generates an MRN. '''\n","\n","    my_MRN = random.choice(['M','E','D','I','C','A','L'])\n","    for x in range(8):\n","        my_MRN += str(random.randint(0,9))\n","\n","    return my_MRN\n","\n","\n","def generate_phone_number():\n","\n","    ''' Randomly generates a phone number. '''\n","\n","    # generate area code using restrictions above\n","    area_code = random.choice(usable_area_codes)\n","\n","    # generate middle 3 digits\n","    prefix_code = 0\n","    while prefix_code in [0,211,311,411,511,611,711,811,911]:\n","        prefix_code = random.randint(200,999)\n","\n","    # assemble and last 4 digits\n","    phone_number = str(area_code) + '-' + str(prefix_code) + '-' + str(random.randint(0,9999)).zfill(4)\n","\n","    return phone_number\n","\n","\n","def generate_name_suffix():\n","\n","    ''' Randomly generates a name suffix. Generational titles only.  Non-professional. '''\n","\n","    list_of_suffixes = ['Sr.', 'Jr.', 'II', 'III', 'IV']\n","\n","    suffix = str(random.choices(list_of_suffixes, weights = [100,100,100,50,10])[0])\n","\n","    return suffix\n","\n","\n","def generate_email(person_name, person_surname):\n","\n","    ''' Randomly generates an email address. '''\n","\n","    # random flip-flop\n","    if random.random() < 0.5:\n","        store_me = person_name\n","        person_name = person_surname\n","        person_surname = store_me\n","\n","    person_email = random.choice([person_name, (person_name + \"_\"), (person_name + '.'), \"\"])\n","    person_email += person_surname + str(random.randint(1,999)) + '@'\n","    person_email += random.choices(DF_email_domains['domain'], weights = DF_email_domains['count'])[0].strip()\n","\n","    return person_email\n","\n","\n","def cumulative_distribution(x, x0, gamma):\n","\n","    ''' Calculates a percentage distribution based on x0 and gamma values. x is a the independent variable.  '''\n","\n","    return(1.0 / math.pi * math.atan(( x - x0) / gamma) + 0.5)\n","\n","\n","def main():\n","\n","    # Prep the main output file\n","    header = 'name,middle_name,surname,name_suffix,age,race,ethnicity,sex,DOB,SSN,MRN,street,city,county,state,zip,country,cell_phone,home_phone,work_phone,email'.upper() + \"\\n\"\n","\n","    with open(output_file_name, 'w') as file:\n","        \n","        file.write(header)\n","\n","    # Loop to create specificed number of records\n","    for x in tqdm(range(number_of_records)):\n","\n","        # Generate basic demographics\n","        person_race, person_ethnicity = generate_race()\n","        person_sex = generate_sex()\n","        person_age = generate_age(person_sex)\n","        person_DOB = generate_DOB(person_age)\n","\n","        # generate names, middles names, surnames, and generational suffixes\n","        person_surname = generate_surname(person_race, person_ethnicity, person_sex)\n","        person_name = generate_name(person_sex, (str(person_DOB)[0:4]))\n","        person_middle_name = person_name\n","        while person_middle_name == person_name:\n","            person_middle_name = generate_name(person_sex, (str(person_DOB)[0:4]))\n","\n","        if person_sex == 'Male' and person_age > 20 and random.random() < 0.01:\n","            person_name_suffix = generate_name_suffix()\n","        else:\n","            person_name_suffix = \"\"\n","\n","        # Generate unique identification numbers\n","        person_SSN = '000-00-0000'\n","        while person_SSN in SSN_list:\n","            person_SSN = generate_SSN()\n","        SSN_list.append(person_SSN)\n","\n","        person_MRN = 'M00000000'\n","        while person_MRN in MRN_list:\n","            person_MRN = generate_MRN()\n","        MRN_list.append(person_MRN)\n","\n","        # reset values\n","        person_cell_phone = \"\"\n","        person_home_phone = \"\"\n","        person_work_phone = \"\"\n","\n","        # Chance for person to have email based on age\n","        if random.random() < cumulative_distribution(person_age, 8, 3):\n","            person_email = generate_email(person_name, person_surname)\n","\n","        # Chance for person to have phone numbers based on age\n","        if random.random() < (0.97 * cumulative_distribution(person_age, 10, 3)):\n","            person_cell_phone = generate_phone_number()\n","        if random.random() < (0.40 * cumulative_distribution(person_age, 15, 4)):\n","            person_home_phone = generate_phone_number()\n","        if random.random() < (0.75 * cumulative_distribution(person_age, 20, 5)):\n","            person_work_phone = generate_phone_number()\n","\n","        # Create an address\n","        person_zip = generate_zip_code()\n","        person_street, person_city, person_county, person_state, person_country = generate_address(person_zip, True)\n","        \n","        # Create the record for writing\n","        new_record = '{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}\\n'.format(\n","            person_name, \n","            person_middle_name, \n","            person_surname, \n","            person_name_suffix, \n","            person_age, \n","            person_race, \n","            person_ethnicity, \n","            person_sex, \n","            person_DOB, \n","            person_SSN, \n","            person_MRN, \n","            person_street, \n","            person_city, \n","            person_county, \n","            person_state, \n","            person_zip, \n","            person_country, \n","            person_cell_phone, \n","            person_home_phone, \n","            person_work_phone, \n","            person_email\n","            )\n","            \n","        with open((output_file_name), 'a') as file:\n","            file.write(new_record)\n","\n","    print('{} records generated and written to {}'.format(number_of_records, output_file_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uz5BInTRcfY1"},"source":["'''if __name__ == \"__main__\":\n","    main()'''\n","\n","# Run the main routine\n","main()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J_UaeUMfXY43"},"source":["# Basic unit tests to go here, to ensure that I (Tony) don't break any intended behaviors of the code"],"execution_count":null,"outputs":[]}]}